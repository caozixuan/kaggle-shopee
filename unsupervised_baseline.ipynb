{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文件路径\n",
    "CSV_PATH = './data/match/'\n",
    "DATA_PATH = './data/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2, matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getMatric用于衡量最终表现\n",
    "def getMetric(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True代表读取训练集数据，而False代表读取测试集数据\n",
    "COMPUTE_CV = True\n",
    "\n",
    "if COMPUTE_CV:\n",
    "    train = pd.read_csv(CSV_PATH + 'train.csv')\n",
    "    train['image'] = DATA_PATH + 'train_images/' + train['image']\n",
    "    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    train['target'] = train.label_group.map(tmp)\n",
    "else:\n",
    "    train = pd.read_csv(CSV_PATH + 'test.csv')\n",
    "    train['image'] = DATA_PATH + 'test_images/' + train['image']\n",
    "print('train shape is', train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()\n",
    "train['oof_hash'] = train.image_phash.map(tmp)\n",
    "\n",
    "# hash比较算法，最后f1可到0.553\n",
    "if COMPUTE_CV:\n",
    "    train['f1'] = train.apply(getMetric('oof_hash'),axis=1)\n",
    "    print('CV score for baseline =',train.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeImageDataset(Dataset):\n",
    "    def __init__(self, img_path, transform):\n",
    "        self.img_path = img_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图像数据\n",
    "imagedataset = ShopeeImageDataset(\n",
    "    train['image'].values,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "imageloader = torch.utils.data.DataLoader(\n",
    "    imagedataset,\n",
    "    batch_size=40, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用预训练的Resnet18\n",
    "class ShopeeImageEmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShopeeImageEmbeddingNet, self).__init__()\n",
    "\n",
    "        model = models.resnet18(True)\n",
    "        model.avgpool = nn.AdaptiveMaxPool2d(output_size=(1, 1))\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "        model.eval()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图片的Embedding\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "imgmodel = ShopeeImageEmbeddingNet()\n",
    "imgmodel = imgmodel.to(DEVICE)\n",
    "\n",
    "imagefeat = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm_notebook(imageloader):\n",
    "        data = data.to(DEVICE)\n",
    "        feat = imgmodel(data)\n",
    "        feat = feat.reshape(feat.shape[0], feat.shape[1])\n",
    "        feat = feat.data.cpu().numpy()\n",
    "\n",
    "        imagefeat.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# 对数据做归一化\n",
    "imagefeat = np.vstack(imagefeat)\n",
    "imagefeat = normalize(imagefeat)\n",
    "\n",
    "imagefeat = torch.from_numpy(imagefeat)\n",
    "imagefeat = imagefeat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "\n",
    "print('Finding similar images...')\n",
    "CTS = len(imagefeat)//CHUNK\n",
    "if len(imagefeat)%CHUNK!=0: CTS += 1\n",
    "for j in range( CTS ):\n",
    "    \n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b, len(imagefeat))\n",
    "    print('chunk',a,'to',b)\n",
    "    \n",
    "    distances = torch.matmul(imagefeat, imagefeat[a:b].T).T\n",
    "    distances = distances.data.cpu().numpy()\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        IDX = np.where(distances[k,]>0.95)[0][:]\n",
    "        o = train.iloc[IDX].posting_id.values\n",
    "        preds.append(o)\n",
    "        \n",
    "del imagefeat, imgmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于image的embedding，f1可以到0.653\n",
    "train['oof_cnn'] = preds\n",
    "\n",
    "if COMPUTE_CV:\n",
    "    train['f1'] = train.apply(getMetric('oof_cnn'),axis=1)\n",
    "    print('CV score for baseline =',train.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model = TfidfVectorizer(stop_words=None, binary=True, max_features=55000)\n",
    "text_embeddings = model.fit_transform(train.title).toarray()\n",
    "print('text embeddings shape',text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = torch.from_numpy(text_embeddings)\n",
    "text_embeddings = text_embeddings.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "print('Finding similar titles...')\n",
    "CTS = len(train)//CHUNK\n",
    "if len(train)%CHUNK!=0: CTS += 1\n",
    "CTS_index = 0\n",
    "for j in range( CTS ):\n",
    "    \n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b,len(train))\n",
    "    print('chunk',a,'to',b)\n",
    "    \n",
    "    # COSINE SIMILARITY DISTANCE\n",
    "    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n",
    "    cts = torch.matmul(text_embeddings, text_embeddings[a:b].T).T\n",
    "    cts = cts.data.cpu().numpy()\n",
    "    print(cts.shape)\n",
    "    for k in range(b-a):\n",
    "        # IDX = np.where(cts[k,]>0.7)[0]\n",
    "        IDX = np.where(cts[k,]>0.7)[0]\n",
    "        o = train.iloc[IDX].posting_id.values\n",
    "        preds.append(o)\n",
    "        CTS_index += 1\n",
    "# del model, text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['oof_text'] = preds\n",
    "\n",
    "if COMPUTE_CV:\n",
    "    train['f1'] = train.apply(getMetric('oof_text'),axis=1)\n",
    "    print('CV score for baseline =',train.f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_for_sub(row):\n",
    "    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n",
    "    return ' '.join( np.unique(x) )\n",
    "\n",
    "def combine_for_cv(row):\n",
    "    x = np.concatenate([row.oof_text,row.oof_cnn, row.oof_hash])\n",
    "    return np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集上可以到0.734，测试集上有0.72\n",
    "if COMPUTE_CV:\n",
    "    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    train['target'] = train.label_group.map(tmp)\n",
    "    train['oof'] = train.apply(combine_for_cv,axis=1)\n",
    "    train['f1'] = train.apply(getMetric('oof'),axis=1)\n",
    "    print('CV Score =', train.f1.mean() )\n",
    "\n",
    "train['matches'] = train.apply(combine_for_sub,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['posting_id','matches']].to_csv('submission.csv',index=False)\n",
    "sub = pd.read_csv('submission.csv')\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
